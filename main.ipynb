{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac6ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "# Import utils\n",
    "from utils.Logger import Logger\n",
    "from utils.Seed import set_seed\n",
    "from utils.Splitter import stratified_split\n",
    "from classes.FeatureDataset.CombinedFeatureDataset import CombinedFeatureDataset\n",
    "from classes.FeatureDataset.WaveformFeatureDataset import WaveformFeatureDataset\n",
    "from classes.FeatureDataset.ListDataset import ListDataset\n",
    "\n",
    "# Import RawNet1 components\n",
    "from classes.models.RawNets.RawNet1.model_RawNet1_preprocessed import RawNet\n",
    "from classes.models.RawNets.RawNet1.trainer_RawNet1 import test_rawnet1, load_model_rawnet1, test_rawnet1_with_loaders\n",
    "\n",
    "# Import RawNet2 components\n",
    "from classes.models.RawNets.RawNet2.model_RawNet2_preprocessed import RawNet2\n",
    "from classes.models.RawNets.RawNet2.trainer_RawNet2 import test_rawnet2, load_model_rawnet2, test_rawnet2_with_loaders\n",
    "\n",
    "# Import RawNet3 components\n",
    "from classes.models.RawNets.RawNet3.model_RawNet3_preprocessed import RawNet3\n",
    "from classes.models.RawNets.RawNet3.trainer_RawNet3 import test_rawnet3, load_model_rawnet3, test_rawnet3_with_loaders\n",
    "\n",
    "seed = 42\n",
    "set_seed(42)\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa55380",
   "metadata": {},
   "source": [
    "# Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfda3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples will be stored here:\n",
    "combined_test_samples = {\n",
    "    \"spoof elevenmultilingualv2 converted samples\": [],\n",
    "    \"spoof elevenmultilingualv2 tts samples\": [],\n",
    "    \"spoof dupdub converted samples\": [],\n",
    "    \"spoof dupdub tts samples\": [],\n",
    "    \"spoof dupdub notindataset tts samples\": [],\n",
    "    \"spoof facebookmms converted samples\": [],\n",
    "    \"spoof facebookmms tts samples\": [],\n",
    "    \"spoof googletts converted samples\": [],\n",
    "    \"spoof googletts tts samples\": [],\n",
    "    \"spoof vits converted samples\": [],\n",
    "    \"spoof vits tts samples\": [],\n",
    "    \"bonafide commonvoice samples\": [],\n",
    "    \"bonafide prosa samples\": [],\n",
    "\n",
    "    \"unseen all samples\": [],\n",
    "    \"seen all samples\": [],\n",
    "\n",
    "    \"spoof all samples\": [],\n",
    "    \"bonafide all samples\": []\n",
    "}\n",
    "\n",
    "# unseen spoof datasets\n",
    "combined_spoof_elevenmultilingualv2_converted_dir = \"test_preprocessed_data/combined/Spoof/Converted/ElevenMultilingualV2\"\n",
    "combined_spoof_elevenmultilingualv2_tts_dir = \"test_preprocessed_data/combined/Spoof/TTS/ElevenMultilingualV2\"\n",
    "combined_spoof_dupdub_converted_dir = \"test_preprocessed_data/combined/Spoof/Converted/DupDub\"\n",
    "combined_spoof_dupdub_tts_dir = \"test_preprocessed_data/combined/Spoof/TTS/DupDub\"\n",
    "combined_spoof_dupdub_notindataset_tts_dir = \"test_preprocessed_data/combined/Spoof/TTS/DupDub-NotInDataset\"\n",
    "\n",
    "# seen spoof datasets\n",
    "combined_spoof_facebookmms_converted_dir = \"preprocessed_data/combined/Spoof/Converted/FacebookMMS\"\n",
    "combined_spoof_facebookmms_tts_dir = \"preprocessed_data/combined/Spoof/TTS/FacebookMMS\"\n",
    "combined_spoof_googletts_converted_dir = \"preprocessed_data/combined/Spoof/Converted/GoogleTTS\"\n",
    "combined_spoof_googletts_tts_dir = \"preprocessed_data/combined/Spoof/TTS/GoogleTTS\"\n",
    "combined_spoof_vits_converted_dir = \"preprocessed_data/combined/Spoof/Converted/VITS\"\n",
    "combined_spoof_vits_tts_dir = \"preprocessed_data/combined/Spoof/TTS/VITS\"\n",
    "\n",
    "# Bonafide datasets (split each, DataLoader per split, do not combine)\n",
    "combined_bonafide_commonvoice_dir = \"preprocessed_data/combined/Bonafide/CommonVoice\"\n",
    "combined_bonafide_prosa_dir = \"preprocessed_data/combined/Bonafide/Prosa\"\n",
    "\n",
    "## ------------------------------------\n",
    "## UNSEEN SPOOF DATASETS\n",
    "## ------------------------------------\n",
    "\n",
    "# ElevenMultilingualV2 Converted\n",
    "if os.path.exists(combined_spoof_elevenmultilingualv2_converted_dir):\n",
    "    combined_spoof_elevenmultilingualv2_converted_dataset = CombinedFeatureDataset(combined_spoof_elevenmultilingualv2_converted_dir, force_label=0)\n",
    "    combined_spoof_elevenmultilingualv2_converted_list = ListDataset([(features, 0) for features, _ in combined_spoof_elevenmultilingualv2_converted_dataset.samples])\n",
    "    combined_test_samples[\"spoof elevenmultilingualv2 converted samples\"].extend(combined_spoof_elevenmultilingualv2_converted_list)\n",
    "    combined_test_samples[\"spoof all samples\"].extend(combined_spoof_elevenmultilingualv2_converted_list)\n",
    "    combined_test_samples[\"unseen all samples\"].extend(combined_spoof_elevenmultilingualv2_converted_list)\n",
    "\n",
    "    print(f\"Loaded {len(combined_spoof_elevenmultilingualv2_converted_list)} samples from {combined_spoof_elevenmultilingualv2_converted_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {combined_spoof_elevenmultilingualv2_converted_dir}\")\n",
    "\n",
    "# ElevenMultilingualV2 TTS\n",
    "if os.path.exists(combined_spoof_elevenmultilingualv2_tts_dir):\n",
    "    combined_spoof_elevenmultilingualv2_tts_dataset = CombinedFeatureDataset(combined_spoof_elevenmultilingualv2_tts_dir, force_label=0)\n",
    "    combined_spoof_elevenmultilingualv2_tts_list = ListDataset([(features, 0) for features, _ in combined_spoof_elevenmultilingualv2_tts_dataset.samples])\n",
    "    combined_test_samples[\"spoof elevenmultilingualv2 tts samples\"].extend(combined_spoof_elevenmultilingualv2_tts_list)\n",
    "    combined_test_samples[\"spoof all samples\"].extend(combined_spoof_elevenmultilingualv2_tts_list)\n",
    "    combined_test_samples[\"unseen all samples\"].extend(combined_spoof_elevenmultilingualv2_tts_list)\n",
    "\n",
    "    print(f\"Loaded {len(combined_spoof_elevenmultilingualv2_tts_list)} samples from {combined_spoof_elevenmultilingualv2_tts_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {combined_spoof_elevenmultilingualv2_tts_dir}\")\n",
    "\n",
    "# DupDub Converted\n",
    "if os.path.exists(combined_spoof_dupdub_converted_dir):\n",
    "    combined_spoof_dupdub_converted_dataset = CombinedFeatureDataset(combined_spoof_dupdub_converted_dir, force_label=0)\n",
    "    combined_spoof_dupdub_converted_list = ListDataset([(features, 0) for features, _ in combined_spoof_dupdub_converted_dataset.samples])\n",
    "    combined_test_samples[\"spoof dupdub converted samples\"].extend(combined_spoof_dupdub_converted_list)\n",
    "    combined_test_samples[\"spoof all samples\"].extend(combined_spoof_dupdub_converted_list)\n",
    "    combined_test_samples[\"unseen all samples\"].extend(combined_spoof_dupdub_converted_list)\n",
    "\n",
    "    print(f\"Loaded {len(combined_spoof_dupdub_converted_list)} samples from {combined_spoof_dupdub_converted_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {combined_spoof_dupdub_converted_dir}\")\n",
    "\n",
    "# DupDub TTS\n",
    "if os.path.exists(combined_spoof_dupdub_tts_dir):\n",
    "    combined_spoof_dupdub_tts_dataset = CombinedFeatureDataset(combined_spoof_dupdub_tts_dir, force_label=0)\n",
    "    combined_spoof_dupdub_tts_list = ListDataset([(features, 0) for features, _ in combined_spoof_dupdub_tts_dataset.samples])\n",
    "    combined_test_samples[\"spoof dupdub tts samples\"].extend(combined_spoof_dupdub_tts_list)\n",
    "    combined_test_samples[\"spoof all samples\"].extend(combined_spoof_dupdub_tts_list)\n",
    "    combined_test_samples[\"unseen all samples\"].extend(combined_spoof_dupdub_tts_list)\n",
    "\n",
    "    print(f\"Loaded {len(combined_spoof_dupdub_tts_list)} samples from {combined_spoof_dupdub_tts_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {combined_spoof_dupdub_tts_dir}\")\n",
    "\n",
    "# DupDub NotInDataset TTS\n",
    "if os.path.exists(combined_spoof_dupdub_notindataset_tts_dir):\n",
    "    combined_spoof_dupdub_notindataset_tts_dataset = CombinedFeatureDataset(combined_spoof_dupdub_notindataset_tts_dir, force_label=0)\n",
    "    combined_spoof_dupdub_notindataset_tts_list = ListDataset([(features, 0) for features, _ in combined_spoof_dupdub_notindataset_tts_dataset.samples])\n",
    "    combined_test_samples[\"spoof dupdub notindataset tts samples\"].extend(combined_spoof_dupdub_notindataset_tts_list)\n",
    "    combined_test_samples[\"spoof all samples\"].extend(combined_spoof_dupdub_notindataset_tts_list)\n",
    "    combined_test_samples[\"unseen all samples\"].extend(combined_spoof_dupdub_notindataset_tts_list)\n",
    "\n",
    "    print(f\"Loaded {len(combined_spoof_dupdub_notindataset_tts_list)} samples from {combined_spoof_dupdub_notindataset_tts_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {combined_spoof_dupdub_notindataset_tts_dir}\")\n",
    "\n",
    "## ------------------------------------\n",
    "## SEEN SPOOF DATASETS\n",
    "## ------------------------------------\n",
    "\n",
    "# FacebookMMS Converted\n",
    "if os.path.exists(combined_spoof_facebookmms_converted_dir):\n",
    "    dataset_combined_spoof_facebookmms_converted = CombinedFeatureDataset(combined_spoof_facebookmms_converted_dir, force_label=0)\n",
    "    combined_spoof_facebookmms_converted = ListDataset([(features, 0) for features, _ in dataset_combined_spoof_facebookmms_converted.samples])\n",
    "    t_fmc, v_fmc, te_fmc = stratified_split(combined_spoof_facebookmms_converted, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "\n",
    "    combined_spoof_facebookmms_converted_list = ListDataset([combined_spoof_facebookmms_converted[i] for i in range(len(te_fmc))])\n",
    "    combined_test_samples[\"spoof facebookmms converted samples\"].extend(combined_spoof_facebookmms_converted_list)\n",
    "    combined_test_samples[\"spoof all samples\"].extend(combined_spoof_facebookmms_converted_list)\n",
    "    combined_test_samples[\"seen all samples\"].extend(combined_spoof_facebookmms_converted_list)\n",
    "\n",
    "    print(f\"Loaded {len(combined_spoof_facebookmms_converted_list)} samples from {combined_spoof_facebookmms_converted_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {combined_spoof_facebookmms_converted_dir}\")\n",
    "\n",
    "# FacebookMMS TTS\n",
    "if os.path.exists(combined_spoof_facebookmms_tts_dir):\n",
    "    dataset_combined_spoof_facebookmms_tts = CombinedFeatureDataset(combined_spoof_facebookmms_tts_dir, force_label=0)\n",
    "    combined_spoof_facebookmms_tts = ListDataset([(features, 0) for features, _ in dataset_combined_spoof_facebookmms_tts.samples])\n",
    "    t_fmt, v_fmt, te_fmt = stratified_split(combined_spoof_facebookmms_tts, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "    \n",
    "    combined_spoof_facebookmms_tts_list = ListDataset([combined_spoof_facebookmms_tts[i] for i in range(len(te_fmt))])\n",
    "    combined_test_samples[\"spoof facebookmms tts samples\"].extend(combined_spoof_facebookmms_tts_list)\n",
    "    combined_test_samples[\"spoof all samples\"].extend(combined_spoof_facebookmms_tts_list)\n",
    "    combined_test_samples[\"seen all samples\"].extend(combined_spoof_facebookmms_tts_list)\n",
    "\n",
    "    print(f\"Loaded {len(combined_spoof_facebookmms_tts_list)} samples from {combined_spoof_facebookmms_tts_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {combined_spoof_facebookmms_tts_dir}\")\n",
    "\n",
    "# GoogleTTS Converted\n",
    "if os.path.exists(combined_spoof_googletts_converted_dir):\n",
    "    dataset_combined_spoof_googletts_converted = CombinedFeatureDataset(combined_spoof_googletts_converted_dir, force_label=0)\n",
    "    combined_spoof_googletts_converted = ListDataset([(features, 0) for features, _ in dataset_combined_spoof_googletts_converted.samples])\n",
    "    t_gtc, v_gtc, te_gtc = stratified_split(combined_spoof_googletts_converted, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "\n",
    "    combined_spoof_googletts_converted_list = ListDataset([combined_spoof_googletts_converted[i] for i in range(len(te_gtc))])\n",
    "    combined_test_samples[\"spoof googletts converted samples\"].extend(combined_spoof_googletts_converted_list)\n",
    "    combined_test_samples[\"spoof all samples\"].extend(combined_spoof_googletts_converted_list)\n",
    "    combined_test_samples[\"seen all samples\"].extend(combined_spoof_googletts_converted_list)\n",
    "\n",
    "    print(f\"Loaded {len(combined_spoof_googletts_converted_list)} samples from {combined_spoof_googletts_converted_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {combined_spoof_googletts_converted_dir}\")\n",
    "\n",
    "# GoogleTTS TTS\n",
    "if os.path.exists(combined_spoof_googletts_tts_dir):\n",
    "    dataset_combined_spoof_googletts_tts = CombinedFeatureDataset(combined_spoof_googletts_tts_dir, force_label=0)\n",
    "    combined_spoof_googletts_tts = ListDataset([(features, 0) for features, _ in dataset_combined_spoof_googletts_tts.samples])\n",
    "    t_gtt, v_gtt, te_gtt = stratified_split(combined_spoof_googletts_tts, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "\n",
    "    combined_spoof_googletts_tts_list = ListDataset([combined_spoof_googletts_tts[i] for i in range(len(te_gtt))])\n",
    "    combined_test_samples[\"spoof googletts tts samples\"].extend(combined_spoof_googletts_tts_list)\n",
    "    combined_test_samples[\"spoof all samples\"].extend(combined_spoof_googletts_tts_list)\n",
    "    combined_test_samples[\"seen all samples\"].extend(combined_spoof_googletts_tts_list)\n",
    "\n",
    "    print(f\"Loaded {len(combined_spoof_googletts_tts_list)} samples from {combined_spoof_googletts_tts_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {combined_spoof_googletts_tts_dir}\")\n",
    "\n",
    "# VITS Converted\n",
    "if os.path.exists(combined_spoof_vits_converted_dir):\n",
    "    dataset_combined_spoof_vits_converted = CombinedFeatureDataset(combined_spoof_vits_converted_dir, force_label=0)\n",
    "    combined_spoof_vits_converted = ListDataset([(features, 0) for features, _ in dataset_combined_spoof_vits_converted.samples])\n",
    "    t_vc, v_vc, te_vc = stratified_split(combined_spoof_vits_converted, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "\n",
    "    combined_spoof_vits_converted_list = ListDataset([combined_spoof_vits_converted[i] for i in range(len(te_vc))])\n",
    "    combined_test_samples[\"spoof vits converted samples\"].extend(combined_spoof_vits_converted_list)\n",
    "    combined_test_samples[\"spoof all samples\"].extend(combined_spoof_vits_converted_list)\n",
    "    combined_test_samples[\"seen all samples\"].extend(combined_spoof_vits_converted_list)\n",
    "\n",
    "    print(f\"Loaded {len(combined_spoof_vits_converted_list)} samples from {combined_spoof_vits_converted_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {combined_spoof_vits_converted_dir}\")\n",
    "\n",
    "# VITS TTS\n",
    "if os.path.exists(combined_spoof_vits_tts_dir):\n",
    "    dataset_combined_spoof_vits_tts = CombinedFeatureDataset(combined_spoof_vits_tts_dir, force_label=0)\n",
    "    combined_spoof_vits_tts = ListDataset([(features, 0) for features, _ in dataset_combined_spoof_vits_tts.samples])\n",
    "    t_vt, v_vt, te_vt = stratified_split(combined_spoof_vits_tts, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "\n",
    "    combined_spoof_vits_tts_list = ListDataset([combined_spoof_vits_tts[i] for i in range(len(te_vt))])\n",
    "    combined_test_samples[\"spoof vits tts samples\"].extend(combined_spoof_vits_tts_list)\n",
    "    combined_test_samples[\"spoof all samples\"].extend(combined_spoof_vits_tts_list)\n",
    "    combined_test_samples[\"seen all samples\"].extend(combined_spoof_vits_tts_list)\n",
    "\n",
    "    print(f\"Loaded {len(combined_spoof_vits_tts_list)} samples from {combined_spoof_vits_tts_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {combined_spoof_vits_tts_dir}\")\n",
    "\n",
    "# Bonafide CommonVoice\n",
    "if os.path.exists(combined_bonafide_commonvoice_dir):\n",
    "    dataset_commonvoice = CombinedFeatureDataset(combined_bonafide_commonvoice_dir, force_label=1)\n",
    "    combined_bonafide_commonvoice = ListDataset([(features, 1) for features, _ in dataset_commonvoice.samples])\n",
    "    t_c, v_c, te_c = stratified_split(combined_bonafide_commonvoice, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "\n",
    "    combined_bonafide_commonvoice_list = ListDataset([combined_bonafide_commonvoice[i] for i in range(len(te_c))])\n",
    "    combined_test_samples[\"bonafide commonvoice samples\"].extend(combined_bonafide_commonvoice_list)\n",
    "    combined_test_samples[\"bonafide all samples\"].extend(combined_bonafide_commonvoice_list)\n",
    "    combined_test_samples[\"seen all samples\"].extend(combined_bonafide_commonvoice_list)\n",
    "\n",
    "    print(f\"Loaded {len(combined_bonafide_commonvoice_list)} samples from {combined_bonafide_commonvoice_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {combined_bonafide_commonvoice_dir}\")\n",
    "\n",
    "# Bonafide Prosa\n",
    "if os.path.exists(combined_bonafide_prosa_dir):\n",
    "    dataset_prosa = CombinedFeatureDataset(combined_bonafide_prosa_dir, force_label=1)\n",
    "    combined_bonafide_prosa = ListDataset([(features, 1) for features, _ in dataset_prosa.samples])\n",
    "    t_p, v_p, te_p = stratified_split(combined_bonafide_prosa, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "\n",
    "    combined_bonafide_prosa_list = ListDataset([combined_bonafide_prosa[i] for i in range(len(te_p))])\n",
    "    combined_test_samples[\"bonafide prosa samples\"].extend(combined_bonafide_prosa_list)\n",
    "    combined_test_samples[\"bonafide all samples\"].extend(combined_bonafide_prosa_list)\n",
    "    combined_test_samples[\"seen all samples\"].extend(combined_bonafide_prosa_list)\n",
    "\n",
    "    print(f\"Loaded {len(combined_bonafide_prosa_list)} samples from {combined_bonafide_prosa_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {combined_bonafide_prosa_dir}\")\n",
    "\n",
    "print(\"-----------------------------------------------\")\n",
    "print(f\"Total unseen test spoof samples: {len(combined_test_samples['unseen all samples'])}\")\n",
    "print(f\"Total seen test spoof samples: {len(combined_test_samples['seen all samples'])}\")\n",
    "print(\"-----------------------------------------------\")\n",
    "print(f\"Total test spoof samples: {len(combined_test_samples['spoof all samples'])}\")\n",
    "print(f\"Total test bonafide samples: {len(combined_test_samples['bonafide all samples'])}\")\n",
    "print(\"-----------------------------------------------\")\n",
    "\n",
    "combined_test_samples_dataloaders = {\n",
    "    key: DataLoader(value, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    for key, value in combined_test_samples.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7250af48",
   "metadata": {},
   "source": [
    "## RawNet1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9b442",
   "metadata": {},
   "source": [
    "### Epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bbcd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_config = {\n",
    "    'in_channels': 1,\n",
    "    'first_conv': 3,\n",
    "    'filts': [128, [128, 128], [128, 256], [256, 256]],\n",
    "    'blocks': [2, 4],\n",
    "    'gru_node': 1024,\n",
    "    'nb_gru_layer': 1,\n",
    "    'nb_fc_node': 1024,\n",
    "    'nb_classes': 2\n",
    "}\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet(combined_model_config, device).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet1(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\combined\\RawNet1\\rawnet1_combined-ep_20-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "# Test loop with memory optimizations\n",
    "for key, test_sample in combined_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet1_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5a0bf",
   "metadata": {},
   "source": [
    "### Epoch 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0556842",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_config = {\n",
    "    'in_channels': 1,\n",
    "    'first_conv': 3,\n",
    "    'filts': [128, [128, 128], [128, 256], [256, 256]],\n",
    "    'blocks': [2, 4],\n",
    "    'gru_node': 1024,\n",
    "    'nb_gru_layer': 1,\n",
    "    'nb_fc_node': 1024,\n",
    "    'nb_classes': 2\n",
    "}\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet(combined_model_config, device).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet1(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\combined\\RawNet1\\rawnet1_combined-ep_30-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in combined_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet1_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b478850b",
   "metadata": {},
   "source": [
    "## RawNet2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba303f",
   "metadata": {},
   "source": [
    "### epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e2580",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_config2 = {\n",
    "    'in_channels': 1,\n",
    "    'first_conv': 3,\n",
    "    'filts': [128, [128, 128], [128, 256], [256, 256]],\n",
    "    'blocks': [2, 4],\n",
    "    'gru_node': 1024,\n",
    "    'nb_gru_layer': 1,\n",
    "    'nb_fc_node': 1024,\n",
    "    'nb_classes': 2,\n",
    "    'nb_samp': 16000 * 4 + 24\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet2(combined_model_config2).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet2(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\combined\\RawNet2\\rawnet2_combined-ep_20-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in combined_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet2_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e617d",
   "metadata": {},
   "source": [
    "### epoch 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43af4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_config2 = {\n",
    "    'in_channels': 1,\n",
    "    'first_conv': 3,\n",
    "    'filts': [128, [128, 128], [128, 256], [256, 256]],\n",
    "    'blocks': [2, 4],\n",
    "    'gru_node': 1024,\n",
    "    'nb_gru_layer': 1,\n",
    "    'nb_fc_node': 1024,\n",
    "    'nb_classes': 2,\n",
    "    'nb_samp': 16000 * 4 + 24\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet2(combined_model_config2).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet2(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\combined\\RawNet2\\rawnet2_combined-ep_30-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in combined_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet2_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acef48f",
   "metadata": {},
   "source": [
    "## RawNet3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e99c3",
   "metadata": {},
   "source": [
    "### Epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e279b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_config3 = {\n",
    "    \"nOut\": 2,\n",
    "    \"sinc_stride\": 10,\n",
    "    \"encoder_type\": \"ECA\",\n",
    "    \"log_sinc\": True,\n",
    "    \"norm_sinc\": \"mean_std\",\n",
    "    \"out_bn\": True\n",
    "}\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet3(**combined_model_config3).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet3(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\combined\\RawNet3\\rawnet3_combined-ep_20-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in combined_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet3_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce65e341",
   "metadata": {},
   "source": [
    "### Epoch 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7e94e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_config3 = {\n",
    "    \"nOut\": 2,\n",
    "    \"sinc_stride\": 10,\n",
    "    \"encoder_type\": \"ECA\",\n",
    "    \"log_sinc\": True,\n",
    "    \"norm_sinc\": \"mean_std\",\n",
    "    \"out_bn\": True\n",
    "}\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet3(**combined_model_config3).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet3(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\combined\\RawNet3\\rawnet3_combined-ep_30-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in combined_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet3_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5375d8e",
   "metadata": {},
   "source": [
    "# Combined (ver 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a484742",
   "metadata": {},
   "source": [
    "## RawNet1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb49d43",
   "metadata": {},
   "source": [
    "### Epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e49992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RawNet1 components\n",
    "from classes.models.RawNets.RawNet1.model_RawNet1_preprocessed_diff_pipeline import RawNet as RawNetv2\n",
    "\n",
    "combined_model_config = {\n",
    "    'in_channels': 1,\n",
    "    'first_conv': 3,\n",
    "    'filts': [128, [128, 128], [128, 256], [256, 256]],\n",
    "    'blocks': [2, 4],\n",
    "    'gru_node': 1024,\n",
    "    'nb_gru_layer': 1,\n",
    "    'nb_fc_node': 1024,\n",
    "    'nb_classes': 2\n",
    "}\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNetv2(combined_model_config, device).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet1(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\diff_pipeline\\RawNet1\\rawnet1_diff_pipeline-ep_20-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in combined_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet1_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca08653",
   "metadata": {},
   "source": [
    "### Epoch 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260874de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RawNet1 components\n",
    "from classes.models.RawNets.RawNet1.model_RawNet1_preprocessed_diff_pipeline import RawNet as RawNetv2\n",
    "\n",
    "combined_model_config = {\n",
    "    'in_channels': 1,\n",
    "    'first_conv': 3,\n",
    "    'filts': [128, [128, 128], [128, 256], [256, 256]],\n",
    "    'blocks': [2, 4],\n",
    "    'gru_node': 1024,\n",
    "    'nb_gru_layer': 1,\n",
    "    'nb_fc_node': 1024,\n",
    "    'nb_classes': 2\n",
    "}\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNetv2(combined_model_config, device).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet1(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\diff_pipeline\\RawNet1\\rawnet1_diff_pipeline-ep_30-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in combined_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet1_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38fafc7",
   "metadata": {},
   "source": [
    "## RawNet2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdf8aca",
   "metadata": {},
   "source": [
    "### Epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RawNet1 components\n",
    "from classes.models.RawNets.RawNet1.model_RawNet1_preprocessed_diff_pipeline import RawNet as RawNetv2\n",
    "\n",
    "combined_model_config = {\n",
    "    'in_channels': 1,\n",
    "    'first_conv': 3,\n",
    "    'filts': [128, [128, 128], [128, 256], [256, 256]],\n",
    "    'blocks': [2, 4],\n",
    "    'gru_node': 1024,\n",
    "    'nb_gru_layer': 1,\n",
    "    'nb_fc_node': 1024,\n",
    "    'nb_classes': 2\n",
    "}\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNetv2(combined_model_config, device).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet1(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\diff_pipeline\\RawNet1\\rawnet1_diff_pipeline-ep_20-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in combined_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet1_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45e1108",
   "metadata": {},
   "source": [
    "### Epoch 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd4ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RawNet2 components\n",
    "from classes.models.RawNets.RawNet2.model_RawNet2_preprocessed_diff_pipeline import RawNet2 as RawNet2v2\n",
    "\n",
    "combined_model_config2 = {\n",
    "    'in_channels': 1,\n",
    "    'first_conv': 3,\n",
    "    'filts': [128, [128, 128], [128, 256], [256, 256]],\n",
    "    'blocks': [2, 4],\n",
    "    'gru_node': 1024,\n",
    "    'nb_gru_layer': 1,\n",
    "    'nb_fc_node': 1024,\n",
    "    'nb_classes': 2,\n",
    "    'nb_samp': 16000 * 4\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet2v2(combined_model_config2).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet2(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\diff_pipeline\\RawNet2\\rawnet2_diff_pipeline-ep_30-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in combined_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet2_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7fb44b",
   "metadata": {},
   "source": [
    "## RawNet3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f95d99",
   "metadata": {},
   "source": [
    "### Epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c25229",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_config3 = {\n",
    "    \"nOut\": 2,\n",
    "    \"sinc_stride\": 10,\n",
    "    \"encoder_type\": \"ECA\",\n",
    "    \"log_sinc\": True,\n",
    "    \"norm_sinc\": \"mean_std\",\n",
    "    \"out_bn\": True\n",
    "}\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet3(**combined_model_config3).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet3(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\diff_pipeline\\RawNet3\\rawnet3_combined-ep_20-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in combined_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet3_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cd6d44",
   "metadata": {},
   "source": [
    "### Epoch 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afdc788",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_config3 = {\n",
    "    \"nOut\": 2,\n",
    "    \"sinc_stride\": 10,\n",
    "    \"encoder_type\": \"ECA\",\n",
    "    \"log_sinc\": True,\n",
    "    \"norm_sinc\": \"mean_std\",\n",
    "    \"out_bn\": True\n",
    "}\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet3(**combined_model_config3).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet3(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\diff_pipeline\\RawNet3\\rawnet3_combined-ep_30-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in combined_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet3_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb0ab3",
   "metadata": {},
   "source": [
    "# Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples will be stored here:\n",
    "waveform_test_samples = {\n",
    "    \"spoof elevenmultilingualv2 converted samples\": [],\n",
    "    \"spoof elevenmultilingualv2 tts samples\": [],\n",
    "    \"spoof dupdub converted samples\": [],\n",
    "    \"spoof dupdub tts samples\": [],\n",
    "    \"spoof dupdub notindataset tts samples\": [],\n",
    "    \"spoof facebookmms converted samples\": [],\n",
    "    \"spoof facebookmms tts samples\": [],\n",
    "    \"spoof googletts converted samples\": [],\n",
    "    \"spoof googletts tts samples\": [],\n",
    "    \"spoof vits converted samples\": [],\n",
    "    \"spoof vits tts samples\": [],\n",
    "    \"bonafide commonvoice samples\": [],\n",
    "    \"bonafide prosa samples\": [],\n",
    "\n",
    "    \"unseen all samples\": [],\n",
    "    \"seen all samples\": [],\n",
    "\n",
    "    \"spoof all samples\": [],\n",
    "    \"bonafide all samples\": []\n",
    "}\n",
    "\n",
    "# unseen spoof datasets\n",
    "waveform_spoof_elevenmultilingualv2_converted_dir = \"test_preprocessed_data/waveform/Spoof/Converted/ElevenMultilingualV2\"\n",
    "waveform_spoof_elevenmultilingualv2_tts_dir = \"test_preprocessed_data/waveform/Spoof/TTS/ElevenMultilingualV2\"\n",
    "waveform_spoof_dupdub_converted_dir = \"test_preprocessed_data/waveform/Spoof/Converted/DupDub\"\n",
    "waveform_spoof_dupdub_tts_dir = \"test_preprocessed_data/waveform/Spoof/TTS/DupDub\"\n",
    "waveform_spoof_dupdub_notindataset_tts_dir = \"test_preprocessed_data/waveform/Spoof/TTS/DupDub-NotInDataset\"\n",
    "\n",
    "# seen spoof datasets\n",
    "waveform_spoof_facebookmms_converted_dir = \"preprocessed_data/waveform/Spoof/Converted/FacebookMMS\"\n",
    "waveform_spoof_facebookmms_tts_dir = \"preprocessed_data/waveform/Spoof/TTS/FacebookMMS\"\n",
    "waveform_spoof_googletts_converted_dir = \"preprocessed_data/waveform/Spoof/Converted/GoogleTTS\"\n",
    "waveform_spoof_googletts_tts_dir = \"preprocessed_data/waveform/Spoof/TTS/GoogleTTS\"\n",
    "waveform_spoof_vits_converted_dir = \"preprocessed_data/waveform/Spoof/Converted/VITS\"\n",
    "waveform_spoof_vits_tts_dir = \"preprocessed_data/waveform/Spoof/TTS/VITS\"\n",
    "\n",
    "# Bonafide datasets (split each, DataLoader per split, do not combine)\n",
    "waveform_bonafide_commonvoice_dir = \"preprocessed_data/waveform/Bonafide/CommonVoice\"\n",
    "waveform_bonafide_prosa_dir = \"preprocessed_data/waveform/Bonafide/Prosa\"\n",
    "\n",
    "## ------------------------------------\n",
    "## UNSEEN SPOOF DATASETS\n",
    "## ------------------------------------\n",
    "\n",
    "# ElevenMultilingualV2 Converted\n",
    "if os.path.exists(waveform_spoof_elevenmultilingualv2_converted_dir):\n",
    "    waveform_spoof_elevenmultilingualv2_converted_dataset = WaveformFeatureDataset(waveform_spoof_elevenmultilingualv2_converted_dir, force_label=0)\n",
    "    waveform_spoof_elevenmultilingualv2_converted_list = ListDataset([(features, 0) for features, _ in waveform_spoof_elevenmultilingualv2_converted_dataset.samples])\n",
    "    waveform_test_samples[\"spoof elevenmultilingualv2 converted samples\"].extend(waveform_spoof_elevenmultilingualv2_converted_list)\n",
    "    waveform_test_samples[\"spoof all samples\"].extend(waveform_spoof_elevenmultilingualv2_converted_list)\n",
    "    waveform_test_samples[\"unseen all samples\"].extend(waveform_spoof_elevenmultilingualv2_converted_list)\n",
    "\n",
    "    print(f\"Loaded {len(waveform_spoof_elevenmultilingualv2_converted_list)} samples from {waveform_spoof_elevenmultilingualv2_converted_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {waveform_spoof_elevenmultilingualv2_converted_dir}\")\n",
    "\n",
    "# ElevenMultilingualV2 TTS\n",
    "if os.path.exists(waveform_spoof_elevenmultilingualv2_tts_dir):\n",
    "    waveform_spoof_elevenmultilingualv2_tts_dataset = WaveformFeatureDataset(waveform_spoof_elevenmultilingualv2_tts_dir, force_label=0)\n",
    "    waveform_spoof_elevenmultilingualv2_tts_list = ListDataset([(features, 0) for features, _ in waveform_spoof_elevenmultilingualv2_tts_dataset.samples])\n",
    "    waveform_test_samples[\"spoof elevenmultilingualv2 tts samples\"].extend(waveform_spoof_elevenmultilingualv2_tts_list)\n",
    "    waveform_test_samples[\"spoof all samples\"].extend(waveform_spoof_elevenmultilingualv2_tts_list)\n",
    "    waveform_test_samples[\"unseen all samples\"].extend(waveform_spoof_elevenmultilingualv2_tts_list)\n",
    "\n",
    "    print(f\"Loaded {len(waveform_spoof_elevenmultilingualv2_tts_list)} samples from {waveform_spoof_elevenmultilingualv2_tts_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {waveform_spoof_elevenmultilingualv2_tts_dir}\")\n",
    "\n",
    "# DupDub Converted\n",
    "if os.path.exists(waveform_spoof_dupdub_converted_dir):\n",
    "    waveform_spoof_dupdub_converted_dataset = WaveformFeatureDataset(waveform_spoof_dupdub_converted_dir, force_label=0)\n",
    "    waveform_spoof_dupdub_converted_list = ListDataset([(features, 0) for features, _ in waveform_spoof_dupdub_converted_dataset.samples])\n",
    "    waveform_test_samples[\"spoof dupdub converted samples\"].extend(waveform_spoof_dupdub_converted_list)\n",
    "    waveform_test_samples[\"spoof all samples\"].extend(waveform_spoof_dupdub_converted_list)\n",
    "    waveform_test_samples[\"unseen all samples\"].extend(waveform_spoof_dupdub_converted_list)\n",
    "\n",
    "    print(f\"Loaded {len(waveform_spoof_dupdub_converted_list)} samples from {waveform_spoof_dupdub_converted_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {waveform_spoof_dupdub_converted_dir}\")\n",
    "\n",
    "# DupDub TTS\n",
    "if os.path.exists(waveform_spoof_dupdub_tts_dir):\n",
    "    waveform_spoof_dupdub_tts_dataset = WaveformFeatureDataset(waveform_spoof_dupdub_tts_dir, force_label=0)\n",
    "    waveform_spoof_dupdub_tts_list = ListDataset([(features, 0) for features, _ in waveform_spoof_dupdub_tts_dataset.samples])\n",
    "    waveform_test_samples[\"spoof dupdub tts samples\"].extend(waveform_spoof_dupdub_tts_list)\n",
    "    waveform_test_samples[\"spoof all samples\"].extend(waveform_spoof_dupdub_tts_list)\n",
    "    waveform_test_samples[\"unseen all samples\"].extend(waveform_spoof_dupdub_tts_list)\n",
    "\n",
    "    print(f\"Loaded {len(waveform_spoof_dupdub_tts_list)} samples from {waveform_spoof_dupdub_tts_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {waveform_spoof_dupdub_tts_dir}\")\n",
    "\n",
    "# DupDub NotInDataset TTS\n",
    "if os.path.exists(waveform_spoof_dupdub_notindataset_tts_dir):\n",
    "    waveform_spoof_dupdub_notindataset_tts_dataset = WaveformFeatureDataset(waveform_spoof_dupdub_notindataset_tts_dir, force_label=0)\n",
    "    waveform_spoof_dupdub_notindataset_tts_list = ListDataset([(features, 0) for features, _ in waveform_spoof_dupdub_notindataset_tts_dataset.samples])\n",
    "    waveform_test_samples[\"spoof dupdub notindataset tts samples\"].extend(waveform_spoof_dupdub_notindataset_tts_list)\n",
    "    waveform_test_samples[\"spoof all samples\"].extend(waveform_spoof_dupdub_notindataset_tts_list)\n",
    "    waveform_test_samples[\"unseen all samples\"].extend(waveform_spoof_dupdub_notindataset_tts_list)\n",
    "\n",
    "    print(f\"Loaded {len(waveform_spoof_dupdub_notindataset_tts_list)} samples from {waveform_spoof_dupdub_notindataset_tts_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {waveform_spoof_dupdub_notindataset_tts_dir}\")\n",
    "\n",
    "## ------------------------------------\n",
    "## SEEN SPOOF DATASETS\n",
    "## ------------------------------------\n",
    "\n",
    "# FacebookMMS Converted\n",
    "if os.path.exists(waveform_spoof_facebookmms_converted_dir):\n",
    "    dataset_waveform_spoof_facebookmms_converted = WaveformFeatureDataset(waveform_spoof_facebookmms_converted_dir, force_label=0)\n",
    "    waveform_spoof_facebookmms_converted = ListDataset([(features, 0) for features, _ in dataset_waveform_spoof_facebookmms_converted.samples])\n",
    "    t_fmc, v_fmc, te_fmc = stratified_split(waveform_spoof_facebookmms_converted, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "\n",
    "    waveform_spoof_facebookmms_converted_list = ListDataset([waveform_spoof_facebookmms_converted[i] for i in range(len(te_fmc))])\n",
    "    waveform_test_samples[\"spoof facebookmms converted samples\"].extend(waveform_spoof_facebookmms_converted_list)\n",
    "    waveform_test_samples[\"spoof all samples\"].extend(waveform_spoof_facebookmms_converted_list)\n",
    "    waveform_test_samples[\"seen all samples\"].extend(waveform_spoof_facebookmms_converted_list)\n",
    "\n",
    "    print(f\"Loaded {len(waveform_spoof_facebookmms_converted_list)} samples from {waveform_spoof_facebookmms_converted_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {waveform_spoof_facebookmms_converted_dir}\")\n",
    "\n",
    "# FacebookMMS TTS\n",
    "if os.path.exists(waveform_spoof_facebookmms_tts_dir):\n",
    "    dataset_waveform_spoof_facebookmms_tts = WaveformFeatureDataset(waveform_spoof_facebookmms_tts_dir, force_label=0)\n",
    "    waveform_spoof_facebookmms_tts = ListDataset([(features, 0) for features, _ in dataset_waveform_spoof_facebookmms_tts.samples])\n",
    "    t_fmt, v_fmt, te_fmt = stratified_split(waveform_spoof_facebookmms_tts, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "    \n",
    "    waveform_spoof_facebookmms_tts_list = ListDataset([waveform_spoof_facebookmms_tts[i] for i in range(len(te_fmt))])\n",
    "    waveform_test_samples[\"spoof facebookmms tts samples\"].extend(waveform_spoof_facebookmms_tts_list)\n",
    "    waveform_test_samples[\"spoof all samples\"].extend(waveform_spoof_facebookmms_tts_list)\n",
    "    waveform_test_samples[\"seen all samples\"].extend(waveform_spoof_facebookmms_tts_list)\n",
    "\n",
    "    print(f\"Loaded {len(waveform_spoof_facebookmms_tts_list)} samples from {waveform_spoof_facebookmms_tts_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {waveform_spoof_facebookmms_tts_dir}\")\n",
    "\n",
    "# GoogleTTS Converted\n",
    "if os.path.exists(waveform_spoof_googletts_converted_dir):\n",
    "    dataset_waveform_spoof_googletts_converted = WaveformFeatureDataset(waveform_spoof_googletts_converted_dir, force_label=0)\n",
    "    waveform_spoof_googletts_converted = ListDataset([(features, 0) for features, _ in dataset_waveform_spoof_googletts_converted.samples])\n",
    "    t_gtc, v_gtc, te_gtc = stratified_split(waveform_spoof_googletts_converted, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "\n",
    "    waveform_spoof_googletts_converted_list = ListDataset([waveform_spoof_googletts_converted[i] for i in range(len(te_gtc))])\n",
    "    waveform_test_samples[\"spoof googletts converted samples\"].extend(waveform_spoof_googletts_converted_list)\n",
    "    waveform_test_samples[\"spoof all samples\"].extend(waveform_spoof_googletts_converted_list)\n",
    "    waveform_test_samples[\"seen all samples\"].extend(waveform_spoof_googletts_converted_list)\n",
    "\n",
    "    print(f\"Loaded {len(waveform_spoof_googletts_converted_list)} samples from {waveform_spoof_googletts_converted_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {waveform_spoof_googletts_converted_dir}\")\n",
    "\n",
    "# GoogleTTS TTS\n",
    "if os.path.exists(waveform_spoof_googletts_tts_dir):\n",
    "    dataset_waveform_spoof_googletts_tts = WaveformFeatureDataset(waveform_spoof_googletts_tts_dir, force_label=0)\n",
    "    waveform_spoof_googletts_tts = ListDataset([(features, 0) for features, _ in dataset_waveform_spoof_googletts_tts.samples])\n",
    "    t_gtt, v_gtt, te_gtt = stratified_split(waveform_spoof_googletts_tts, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "\n",
    "    waveform_spoof_googletts_tts_list = ListDataset([waveform_spoof_googletts_tts[i] for i in range(len(te_gtt))])\n",
    "    waveform_test_samples[\"spoof googletts tts samples\"].extend(waveform_spoof_googletts_tts_list)\n",
    "    waveform_test_samples[\"spoof all samples\"].extend(waveform_spoof_googletts_tts_list)\n",
    "    waveform_test_samples[\"seen all samples\"].extend(waveform_spoof_googletts_tts_list)\n",
    "\n",
    "    print(f\"Loaded {len(waveform_spoof_googletts_tts_list)} samples from {waveform_spoof_googletts_tts_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {waveform_spoof_googletts_tts_dir}\")\n",
    "\n",
    "# VITS Converted\n",
    "if os.path.exists(waveform_spoof_vits_converted_dir):\n",
    "    dataset_waveform_spoof_vits_converted = WaveformFeatureDataset(waveform_spoof_vits_converted_dir, force_label=0)\n",
    "    waveform_spoof_vits_converted = ListDataset([(features, 0) for features, _ in dataset_waveform_spoof_vits_converted.samples])\n",
    "    t_vc, v_vc, te_vc = stratified_split(waveform_spoof_vits_converted, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "\n",
    "    waveform_spoof_vits_converted_list = ListDataset([waveform_spoof_vits_converted[i] for i in range(len(te_vc))])\n",
    "    waveform_test_samples[\"spoof vits converted samples\"].extend(waveform_spoof_vits_converted_list)\n",
    "    waveform_test_samples[\"spoof all samples\"].extend(waveform_spoof_vits_converted_list)\n",
    "    waveform_test_samples[\"seen all samples\"].extend(waveform_spoof_vits_converted_list)\n",
    "\n",
    "    print(f\"Loaded {len(waveform_spoof_vits_converted_list)} samples from {waveform_spoof_vits_converted_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {waveform_spoof_vits_converted_dir}\")\n",
    "\n",
    "# VITS TTS\n",
    "if os.path.exists(waveform_spoof_vits_tts_dir):\n",
    "    dataset_waveform_spoof_vits_tts = WaveformFeatureDataset(waveform_spoof_vits_tts_dir, force_label=0)\n",
    "    waveform_spoof_vits_tts = ListDataset([(features, 0) for features, _ in dataset_waveform_spoof_vits_tts.samples])\n",
    "    t_vt, v_vt, te_vt = stratified_split(waveform_spoof_vits_tts, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "\n",
    "    waveform_spoof_vits_tts_list = ListDataset([waveform_spoof_vits_tts[i] for i in range(len(te_vt))])\n",
    "    waveform_test_samples[\"spoof vits tts samples\"].extend(waveform_spoof_vits_tts_list)\n",
    "    waveform_test_samples[\"spoof all samples\"].extend(waveform_spoof_vits_tts_list)\n",
    "    waveform_test_samples[\"seen all samples\"].extend(waveform_spoof_vits_tts_list)\n",
    "\n",
    "    print(f\"Loaded {len(waveform_spoof_vits_tts_list)} samples from {waveform_spoof_vits_tts_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {waveform_spoof_vits_tts_dir}\")\n",
    "\n",
    "# Bonafide CommonVoice\n",
    "if os.path.exists(waveform_bonafide_commonvoice_dir):\n",
    "    dataset_commonvoice = WaveformFeatureDataset(waveform_bonafide_commonvoice_dir, force_label=1)\n",
    "    waveform_bonafide_commonvoice = ListDataset([(features, 1) for features, _ in dataset_commonvoice.samples])\n",
    "    t_c, v_c, te_c = stratified_split(waveform_bonafide_commonvoice, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "\n",
    "    waveform_bonafide_commonvoice_list = ListDataset([waveform_bonafide_commonvoice[i] for i in range(len(te_c))])\n",
    "    waveform_test_samples[\"bonafide commonvoice samples\"].extend(waveform_bonafide_commonvoice_list)\n",
    "    waveform_test_samples[\"bonafide all samples\"].extend(waveform_bonafide_commonvoice_list)\n",
    "    waveform_test_samples[\"seen all samples\"].extend(waveform_bonafide_commonvoice_list)\n",
    "\n",
    "    print(f\"Loaded {len(waveform_bonafide_commonvoice_list)} samples from {waveform_bonafide_commonvoice_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {waveform_bonafide_commonvoice_dir}\")\n",
    "\n",
    "# Bonafide Prosa\n",
    "if os.path.exists(waveform_bonafide_prosa_dir):\n",
    "    dataset_prosa = WaveformFeatureDataset(waveform_bonafide_prosa_dir, force_label=1)\n",
    "    waveform_bonafide_prosa = ListDataset([(features, 1) for features, _ in dataset_prosa.samples])\n",
    "    t_p, v_p, te_p = stratified_split(waveform_bonafide_prosa, splits=(0.7, 0.15, 0.15), seed=seed)\n",
    "\n",
    "    waveform_bonafide_prosa_list = ListDataset([waveform_bonafide_prosa[i] for i in range(len(te_p))])\n",
    "    waveform_test_samples[\"bonafide prosa samples\"].extend(waveform_bonafide_prosa_list)\n",
    "    waveform_test_samples[\"bonafide all samples\"].extend(waveform_bonafide_prosa_list)\n",
    "    waveform_test_samples[\"seen all samples\"].extend(waveform_bonafide_prosa_list)\n",
    "\n",
    "    print(f\"Loaded {len(waveform_bonafide_prosa_list)} samples from {waveform_bonafide_prosa_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Directory not found: {waveform_bonafide_prosa_dir}\")\n",
    "\n",
    "print(\"-----------------------------------------------\")\n",
    "print(f\"Total unseen test spoof samples: {len(waveform_test_samples['unseen all samples'])}\")\n",
    "print(f\"Total seen test spoof samples: {len(waveform_test_samples['seen all samples'])}\")\n",
    "print(\"-----------------------------------------------\")\n",
    "print(f\"Total test spoof samples: {len(waveform_test_samples['spoof all samples'])}\")\n",
    "print(f\"Total test bonafide samples: {len(waveform_test_samples['bonafide all samples'])}\")\n",
    "print(\"-----------------------------------------------\")\n",
    "\n",
    "waveform_test_samples_dataloaders = {\n",
    "    key: DataLoader(value, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    for key, value in waveform_test_samples.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403173b8",
   "metadata": {},
   "source": [
    "## RawNet1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65ea1f",
   "metadata": {},
   "source": [
    "### Epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3da054",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_model_config = {\n",
    "    'in_channels': 1,\n",
    "    'first_conv': 3,\n",
    "    'filts': [128, [128, 128], [128, 256], [256, 256]],\n",
    "    'blocks': [2, 4],\n",
    "    'gru_node': 1024,\n",
    "    'nb_gru_layer': 1,\n",
    "    'nb_fc_node': 1024,\n",
    "    'nb_classes': 2,\n",
    "    'input_length': 16000 * 4\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet(waveform_model_config, device).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet1(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\waveform\\RawNet1\\rawnet1_waveform-ep_20-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in waveform_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet1_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679166a",
   "metadata": {},
   "source": [
    "### Epoch 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f020d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_model_config = {\n",
    "    'in_channels': 1,\n",
    "    'first_conv': 3,\n",
    "    'filts': [128, [128, 128], [128, 256], [256, 256]],\n",
    "    'blocks': [2, 4],\n",
    "    'gru_node': 1024,\n",
    "    'nb_gru_layer': 1,\n",
    "    'nb_fc_node': 1024,\n",
    "    'nb_classes': 2,\n",
    "    'input_length': 16000 * 4\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet(waveform_model_config, device).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet1(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\waveform\\RawNet1\\rawnet1_waveform-ep_30-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in waveform_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet1_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2f337c",
   "metadata": {},
   "source": [
    "## RawNet2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ee1a60",
   "metadata": {},
   "source": [
    "### Epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_model_config2 = {\n",
    "    'in_channels': 1,\n",
    "    'first_conv': 3,\n",
    "    'filts': [128, [128, 128], [128, 256], [256, 256]],\n",
    "    'blocks': [2, 4],\n",
    "    'gru_node': 1024,\n",
    "    'nb_gru_layer': 1,\n",
    "    'nb_fc_node': 1024,\n",
    "    'nb_classes': 2,\n",
    "    'nb_samp': 16000 * 4\n",
    "}\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet2(waveform_model_config2).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet2(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\waveform\\RawNet2\\rawnet2_waveform-ep_20-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in waveform_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet2_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f525a0f6",
   "metadata": {},
   "source": [
    "### Epoch 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_model_config2 = {\n",
    "    'in_channels': 1,\n",
    "    'first_conv': 3,\n",
    "    'filts': [128, [128, 128], [128, 256], [256, 256]],\n",
    "    'blocks': [2, 4],\n",
    "    'gru_node': 1024,\n",
    "    'nb_gru_layer': 1,\n",
    "    'nb_fc_node': 1024,\n",
    "    'nb_classes': 2,\n",
    "    'nb_samp': 16000 * 4\n",
    "}\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet2(waveform_model_config2).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet2(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\waveform\\RawNet2\\rawnet2_waveform-ep_30-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in waveform_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet2_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80042ae",
   "metadata": {},
   "source": [
    "## RawNet3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede54c12",
   "metadata": {},
   "source": [
    "### Epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b13b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_model_config3 = {\n",
    "    \"nOut\": 2,\n",
    "    \"sinc_stride\": 10,\n",
    "    \"encoder_type\": \"ECA\",\n",
    "    \"log_sinc\": True,\n",
    "    \"norm_sinc\": \"mean_std\",\n",
    "    \"out_bn\": True\n",
    "}\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet3(**waveform_model_config3).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet3(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\waveform\\RawNet3\\rawnet3_waveform-ep_20-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in waveform_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet3_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4161b259",
   "metadata": {},
   "source": [
    "### Epoch 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a9a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_model_config3 = {\n",
    "    \"nOut\": 2,\n",
    "    \"sinc_stride\": 10,\n",
    "    \"encoder_type\": \"ECA\",\n",
    "    \"log_sinc\": True,\n",
    "    \"norm_sinc\": \"mean_std\",\n",
    "    \"out_bn\": True\n",
    "}\n",
    "\n",
    "# --- Set up model, optimizer, and scaler ---\n",
    "model = RawNet3(**waveform_model_config3).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- Load the model ---\n",
    "start_epoch = load_model_rawnet3(\n",
    "    model, optimizer, scaler,\n",
    "    path=r\"pretrained_weights\\waveform\\RawNet3\\rawnet3_waveform-ep_30-bs_32-lr_0.0001.pth\"\n",
    ")\n",
    "\n",
    "for key, test_sample in waveform_test_samples_dataloaders.items():\n",
    "    print(f\"Testing {key}\")\n",
    "    predictions = test_rawnet3_with_loaders(model, test_sample, device=device)\n",
    "    print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rawnet-pf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
